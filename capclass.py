# -*- coding: utf-8 -*-
"""CapClass.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/148HPkz9KajZ_tgBVVpa4TCnGfXjywmOz
"""

from keras.preprocessing import image
from keras.preprocessing.image import load_img
from keras.preprocessing.image import img_to_array
from keras.applications.vgg16 import preprocess_input
from PIL import Image as pil_image
from keras.applications.vgg16 import VGG16
from keras.models import Model
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import os, shutil, glob, os.path
import numpy as np
import matplotlib.pyplot as plt
from random import randint
import pandas as pd
import pickle
import torch

# import requests, zipfile, io

# r = requests.get('/content/data.zip') 
# #r = requests.get( 'https://github.com/sydneywehn/DS402/blob/main/data.zip?raw=true' ) 
# z = zipfile.ZipFile(io.BytesIO(r.content))
# z.extractall()

from google.colab import drive
drive.mount('/content/drive')

image.LOAD_TRUNCATED_IMAGES = True
model = VGG16(weights='imagenet', include_top=False)

imdir = '/content/drive/MyDrive/DS440 /Dataset/data'
targetdir = r"/content/drive/MyDrive/DS440/Targetdir"

filelist = glob.glob(os.path.join(imdir, '*.png'))
# filelist.sort()
featurelist = []

# how many images
# print(len(featurelist))

for i, imagepath in enumerate(filelist):
    print("    Status: %s / %s" %(i, len(filelist)), end="\r")
    img = image.load_img(imagepath, target_size=(224, 224))
    img_data = image.img_to_array(img)
    img_data = np.expand_dims(img_data, axis=0)
    img_data = preprocess_input(img_data)
    features = np.array(model.predict(img_data))
    featurelist.append(features.flatten())

import numpy as np

data = '/content/drive/MyDrive/DS440 /Dataset/data'

len(features)

print(features.shape)
# 4210 rows 
# 2048 attributes per image

labels = np.load('/content/labels.npy')

feat = np.load('/content/features.npy')

def get_Labels(labels):
  for all in labels:
    all = all[0][0]
    print(all)

llabelss = []
for all in labels:
  all = all[0][0]
  llabelss.append(all)
print(llabelss)

df = pd.DataFrame(data=llabelss, columns=['Label'])

df['Index'] = df.reset_index().index

df

df1 = pd.DataFrame(data=feat, columns=None)

df1['Index'] = df1.reset_index().index

df1['Label'] = df['Label']

df1

df2 = pd.get_dummies(df1, columns=['Label'])

df2

from sklearn.model_selection import train_test_split
Train, Val = train_test_split(df1, test_size=0.2)
#train, val = train_test_split(train, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2

Train = Train.drop(labels='Label', axis=1)
Val = Val.drop(labels='Label', axis=1)

df1.value_counts(df1.Label)

Train.to_csv('/content/drive/MyDrive/DS440 /Dataset/Manual/Preprocessed/Train.csv')
Val.to_csv('/content/drive/MyDrive/DS440 /Dataset/Manual/Preprocessed/Validation.csv')

! pip install torchvision

from torchvision import datasets, models, transforms

print('train len ', len(Train))
print('val len ', len(Val))
#print('test len ', len(test))
print('total len ', len(df1))

# Make transforms and use data loaders

# We'll use these a lot, so make them variables
mean_nums = [0.485, 0.456, 0.406]
std_nums = [0.229, 0.224, 0.225]

chosen_transforms = {'Train': transforms.Compose([
        transforms.RandomResizedCrop(size=256),
        transforms.RandomRotation(degrees=15),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize(mean_nums, std_nums)
]), 'Val': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize(mean_nums, std_nums)
]),
}

# mean_nums = [0.485, 0.456, 0.406]
# std_nums = [0.229, 0.224, 0.225]

# from torchvision import transforms
# transform = transforms.Compose([
#         transforms.RandomResizedCrop(size=256),
#         transforms.RandomRotation(degrees=15),
#         transforms.RandomHorizontalFlip(),
#         transforms.ToTensor(),
#         transforms.Normalize(mean_nums, std_nums)])

! pip3 install torchvision as tv

import torchvision as tv
data_path = '/content/drive/MyDrive/DS440 /Dataset/Manual/Preprocessed/'

Train

Val

# Use the image folder function to create datasets
chosen_datasets = {x: datasets.ImageFolder(os.path.join(data_path, x),
  chosen_transforms[x])
                  for x in ['Train', 'Val']}

# Make iterables with the dataloaders
dataloaders = {x: torch.utils.data.DataLoader(chosen_datasets[x], batch_size=4,
  shuffle=True, num_workers=4)
              for x in ['Train', 'Val']}

# trainloader = torch.utils.data.DataLoader(
#     train, 
#     batch_size=4, 
#     num_workers=4, 
#     shuffle=True
# )

print(len(dataloaders))

#print(batch[0].shape)
#plt.imshow(batch[0][0].permute(1, 2, 0))
#print(batch[1][0])

dataset_sizes = {x: len(chosen_datasets[x]) for x in ['Train', 'Val']}
class_names = df1['Label']

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

class_names

# Visualize some images
def imshow(inp, title=None):
    inp = inp.numpy().transpose((1, 2, 0))
    mean = np.array([mean_nums])
    std = np.array([std_nums])
    inp = std * inp + mean
    inp = np.clip(inp, 0, 1)
    plt.imshow(inp)
    if title is not None:
        plt.title(title)
    plt.pause(0.001)  # Pause a bit so that plots are updated

# # Grab some of the training data to visualize
# inputs, classes = next(iter(train_loader['train']))

# # Now we construct a grid from batch
# out = torchvision.utils.make_grid(inputs)

# imshow(out, title=[class_names[x] for x in classes])

from torchvision import datasets, models, transforms

"""# Alexnet

"""

# Setting up the model
# load in pretrained and reset final fully connected
alex_mod = models.alexnet(pretrained=True)
alex_mod

import torch.nn as nn

# Changing the last layer of the NN to the correct number of output features
features_num = alex_mod.classifier[6].in_features
alex_mod.classifier[6] = nn.Linear(features_num, 26)

for name, child in alex_mod.named_children():
    print(name)

print(alex_mod)

from __future__ import print_function, division

import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
import torchvision
from torchvision import datasets, models, transforms
import matplotlib.pyplot as plt
import numpy as np
import time
import os
import copy

alex_mod = alex_mod.to(device)
criterion = nn.CrossEntropyLoss()

# Observe that all parameters are being optimized
optimizer_ft = optim.SGD(alex_mod.parameters(), lr=0.001, momentum=0.9)

# Decay LR by a factor of 0.1 every 7 epochs
exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)

accuracy_train=[]
accuracy_val=[]

def train_model(model, criterion, optimizer, scheduler, num_epochs=15):
    since = time.time()

    best_model_wts = copy.deepcopy(model.state_dict())
    best_acc = 0.0

    for epoch in range(num_epochs):
        print('Epoch {}/{}'.format(epoch, num_epochs - 1))
        print('-' * 10)

        # Each epoch has a training and validation phase
        for phase in ['Train', 'Val']:
            if phase == 'Train':
                scheduler.step()
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode

            current_loss = 0.0
            current_corrects = 0

            # Here's where the training happens
            print('Iterating through data...')

            for inputs, labels in dataloaders[phase]:
                inputs = inputs.to(device)
                labels = labels.to(device)

                # We need to zero the gradients, don't forget it
                optimizer.zero_grad()

                # Time to carry out the forward training poss
                # We only need to log the loss stats if we are in training phase
                with torch.set_grad_enabled(phase == 'Train'):
                    outputs = model(inputs)
                    _, preds = torch.max(outputs, 1)
                    loss = criterion(outputs, labels)

                    # backward + optimize only if in training phase
                    if phase == 'Train':
                        loss.backward()
                        optimizer.step()

                # We want variables to hold the loss statistics
                current_loss += loss.item() * inputs.size(0)
                current_corrects += torch.sum(preds == labels.data)

            epoch_loss = current_loss / dataset_sizes[phase]
            epoch_acc = current_corrects.double() / dataset_sizes[phase]

            print('{} Loss: {:.4f} Acc: {:.4f}'.format(
                phase, epoch_loss, epoch_acc))

            # Make a copy of the model if the accuracy on the validation set has improved
            if phase == 'Val' and epoch_acc > best_acc:
                best_acc = epoch_acc
                best_model_wts = copy.deepcopy(model.state_dict())

        print()

    time_since = time.time() - since
    print('Training complete in {:.0f}m {:.0f}s'.format(
        time_since // 60, time_since % 60))
    print('Best val Acc: {:4f}'.format(best_acc))

    # Now we'll load in the best model weights and return it
    model.load_state_dict(best_model_wts)
    return model

def visualize_model(model, num_images=6):
    was_training = model.training
    model.eval()
    images_handeled = 0
    fig = plt.figure()

    with torch.no_grad():
        for i, (inputs, labels) in enumerate(dataloaders['Val']):
            inputs = inputs.to(device)
            labels = labels.to(device)

            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)

            for j in range(inputs.size()[0]):
                images_handeled += 1
                ax = plt.subplot(num_images//2, 2, images_handeled)
                ax.axis('off')
                ax.set_title('predicted: {}'.format(class_names[preds[j]]))
                imshow(inputs.cpu().data[j])

                if images_handeled == num_images:
                    model.train(mode=was_training)
                    return
        model.train(mode=was_training)

base_model = train_model(alex_mod, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=8)
#visualize_model(base_model)
#plt.show()

#Get predictions and labels
import numpy

predlist = []
lbllist = []
with torch.no_grad():
    for i, data in dataloaders['Train']:
       
        inputs= i.to(device)
        classes = data.to(device)
        _, preds = torch.max(base_model(inputs),1)
        # append batch prediction results 
        predlist += list(preds.view(-1).cpu().numpy())
        # ground truth 
        lbllist += list(classes.view(-1).cpu().numpy())

# create confusion matrix 
from sklearn.metrics import confusion_matrix

cm= confusion_matrix(lbllist,predlist)
cm

import itertools
import numpy as np
import matplotlib.pyplot as plt

def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion Matrix', cmap=plt.cm.Greens):
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment="center", color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

folders = [dir for dir in sorted(os.listdir("/content/drive/MyDrive/DS440 /Dataset/Manual/Preprocessed/Train"))]
classes = {folder: i for i, folder in enumerate(folders)};
classes

plt.figure(figsize=(8,8))
plot_confusion_matrix(cm, list(classes.keys()), normalize=False)

# TP TN FP FN for all 4 classes 
FP = cm.sum(axis=0) - np.diag(cm) 
FN = cm.sum(axis=1) - np.diag(cm)
TP = np.diag(cm)
TN = cm.sum() - (FP + FN + TP)
FP = FP.astype(float)
FN = FN.astype(float)
TP = TP.astype(float)
TN = TN.astype(float)
print("TP:", TP)
print("TN:", TN)
print("FP:", FP)
print("FN:", FN)

#Precision, Recall, & F1
from sklearn.metrics import precision_score
from sklearn.metrics import f1_score
from sklearn.metrics import recall_score

precision = precision_score(lbllist, predlist, average='weighted')
f1 = f1_score(lbllist, predlist, average='weighted')
recall = recall_score(lbllist, predlist, average='weighted')

print("precision:", precision)
print("f1:", f1)
print("recall:", recall)

# make lists of train and val acc and return model and those two values 
accuracy_trainn = []
for row in accuracy_train:
  for i in row:
    accuracy_trainn.append(i)
accuracy_vall = []
for row in accuracy_val:
  for i in row:
    accuracy_vall.append(i)

# # Plot 
# import matplotlib.pyplot as plt
# plt.ylabel('Accuracy')
# plt.xlabel('Iteration/Epoch')
# plt.title('Accuracy Plot')
# plt.plot(accuracy_trainn, label='Train')
# plt.plot(accuracy_vall, label='Validation')
# plt.legend()

"""# Resnet34

"""

# Setting up the model
# load in pretrained and reset final fully connected

res_mod = models.resnet34(pretrained=True)

num_ftrs = res_mod.fc.in_features
res_mod.fc = nn.Linear(num_ftrs, 26)

for name, child in res_mod.named_children():
    print(name)

print(res_mod)

res_mod = res_mod.to(device)
criterion = nn.CrossEntropyLoss()

# Observe that all parameters are being optimized
optimizer_ft = optim.SGD(res_mod.parameters(), lr=0.001, momentum=0.9)

# Decay LR by a factor of 0.1 every 7 epochs
exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)

def train_model(res_mod, criterion, optimizer, scheduler, num_epochs=10):
    since = time.time()

    best_model_wts = copy.deepcopy(res_mod.state_dict())
    best_acc = 0.0

    for epoch in range(num_epochs):
        print('Epoch {}/{}'.format(epoch, num_epochs - 1))
        print('-' * 10)

        # Each epoch has a training and validation phase
        for phase in ['Train', 'Val']:
            if phase == 'Train':
                scheduler.step()
                res_mod.train()  # Set model to training mode
            else:
                res_mod.eval()   # Set model to evaluate mode

            current_loss = 0.0
            current_corrects = 0

            # Here's where the training happens
            print('Iterating through data...')

            for inputs, labels in dataloaders[phase]:
                inputs = inputs.to(device)
                labels = labels.to(device)

                # We need to zero the gradients, don't forget it
                optimizer.zero_grad()

                # Time to carry out the forward training poss
                # We only need to log the loss stats if we are in training phase
                with torch.set_grad_enabled(phase == 'Train'):
                    outputs = res_mod(inputs)
                    _, preds = torch.max(outputs, 1)
                    loss = criterion(outputs, labels)

                    # backward + optimize only if in training phase
                    if phase == 'Train':
                        loss.backward()
                        optimizer.step()

                # We want variables to hold the loss statistics
                current_loss += loss.item() * inputs.size(0)
                current_corrects += torch.sum(preds == labels.data)

            epoch_loss = current_loss / dataset_sizes[phase]
            epoch_acc = current_corrects.double() / dataset_sizes[phase]

            print('{} Loss: {:.4f} Acc: {:.4f}'.format(
                phase, epoch_loss, epoch_acc))

            # Make a copy of the model if the accuracy on the validation set has improved
            if phase == 'Val' and epoch_acc > best_acc:
                best_acc = epoch_acc
                best_model_wts = copy.deepcopy(model.state_dict())

        print()

    time_since = time.time() - since
    print('Training complete in {:.0f}m {:.0f}s'.format(
        time_since // 60, time_since % 60))
    print('Best val Acc: {:4f}'.format(best_acc))

    # Now we'll load in the best model weights and return it
    res_mod.load_state_dict(best_model_wts)
    return res_mod

def visualize_model(model, num_images=6):
    was_training = model.training
    model.eval()
    images_handeled = 0
    fig = plt.figure()

    with torch.no_grad():
        for i, (inputs, labels) in enumerate(dataloaders['Val']):
            inputs = inputs.to(device)
            labels = labels.to(device)

            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)

            for j in range(inputs.size()[0]):
                images_handeled += 1
                ax = plt.subplot(num_images//2, 2, images_handeled)
                ax.axis('off')
                ax.set_title('predicted: {}'.format(class_names[preds[j]]))
                imshow(inputs.cpu().data[j])

                if images_handeled == num_images:
                    model.train(mode=was_training)
                    return
        model.train(mode=was_training)

base_model = train_model(res_mod, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=8)
#visualize_model(base_model)
plt.show()

# create confusion matrix 
from sklearn.metrics import confusion_matrix

cm= confusion_matrix(lbllist,predlist)
cm

#Get predictions and labels
import numpy

predlist = []
lbllist = []
with torch.no_grad():
    for i, data in dataloaders['Val']:
       
        inputs= i.to(device)
        classes = data.to(device)
        _, preds = torch.max(base_model(inputs),1)
        # append batch prediction results 
        predlist += list(preds.view(-1).cpu().numpy())
        # ground truth 
        lbllist += list(classes.view(-1).cpu().numpy())

import itertools
import numpy as np
import matplotlib.pyplot as plt

def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion Matrix', cmap=plt.cm.Greens):
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment="center", color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

folders = [dir for dir in sorted(os.listdir("/content/drive/MyDrive/DS440 /Dataset/Manual/Preprocessed/Train"))]
classes = {folder: i for i, folder in enumerate(folders)};
classes

plt.figure(figsize=(8,8))
plot_confusion_matrix(cm, list(classes.keys()), normalize=False)

# TP TN FP FN for all 4 classes 
FP = cm.sum(axis=0) - np.diag(cm) 
FN = cm.sum(axis=1) - np.diag(cm)
TP = np.diag(cm)
TN = cm.sum() - (FP + FN + TP)
FP = FP.astype(float)
FN = FN.astype(float)
TP = TP.astype(float)
TN = TN.astype(float)
print("TP:", TP)
print("TN:", TN)
print("FP:", FP)
print("FN:", FN)

#Precision, Recall, & F1
from sklearn.metrics import precision_score
from sklearn.metrics import f1_score
from sklearn.metrics import recall_score

precision = precision_score(lbllist, predlist, average='weighted')
f1 = f1_score(lbllist, predlist, average='weighted')
recall = recall_score(lbllist, predlist, average='weighted')

print("precision:", precision)
print("f1:", f1)
print("recall:", recall)

# make lists of train and val acc and return model and those two values 
accuracy_trainn = []
for row in accuracy_train:
  for i in row:
    accuracy_trainn.append(i)
accuracy_vall = []
for row in accuracy_val:
  for i in row:
    accuracy_vall.append(i)

# Plot 
# import matplotlib.pyplot as plt
# plt.ylabel('Accuracy')
# plt.xlabel('Iteration/Epoch')
# plt.title('Accuracy Plot')
# plt.plot(accuracy_trainn, label='Train')
# plt.plot(accuracy_vall, label='Validation')
# plt.legend()

! jupyter nbconvert --to html CapClasss.ipynb

"""# Debugging/ Unused Code

"""

model.fit(train_ds,
          epochs=50,
          callbacks=[tensorboard_cb])

label_names = pd.read_csv('/content/drive/MyDrive/DS440 /Dataset/Manual/FeatureVec/Labels.csv')
label_names

class_names = df1['Label']
class_names

# train - 3,368
# test - 843

import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt
import os
import time

from sklearn.model_selection import train_test_split
train, test = train_test_split(df1, test_size=0.2) 
train_classes, test_classes = train_test_split(df1['Label'], test_size=0.2)

train = pd.get_dummies(train, columns=['Label'])
test = pd.get_dummies(test, columns=['Label'])

train_tensor = tf.constant(train, dtype = tf.float32)

train_ds = tf.data.Dataset.from_tensor_slices((train, train_classes))
test_ds = tf.data.Dataset.from_tensor_slices((test, test_classes))

def process_images(image, label):
    # Normalize images to have a mean of 0 and standard deviation of 1
    image = tf.image.per_image_standardization(image)
    # Resize images from 32x32 to 277x277
    image = tf.image.resize(image, (227,227))
    return image, label

train_ds_size = tf.data.experimental.cardinality(train_ds).numpy()
test_ds_size = tf.data.experimental.cardinality(test_ds).numpy()

train_ds = (train_ds
                  .map(process_images)
                  .shuffle(buffer_size=train_ds_size)
                  .batch(batch_size=32, drop_remainder=True))
test_ds = (test_ds
                  .map(process_images)
                  .shuffle(buffer_size=train_ds_size)
                  .batch(batch_size=32, drop_remainder=True))

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import numpy as np
import torchvision
from torchvision import *
from torch.utils.data import Dataset, DataLoader

import matplotlib.pyplot as plt
import time
import copy
import os

batch_size = 128
learning_rate = 1e-3

transforms = transforms.Compose(
[
    transforms.ToTensor()
])

from sklearn.model_selection import train_test_split
train, test = train_test_split(df1, test_size=0.2) 
train_classes, test_classes = train_test_split(df1['Label'], test_size=0.2)

train_dataloader = DataLoader(train, batch_size=batch_size, shuffle=True)
test_dataloader = DataLoader(test, batch_size=batch_size, shuffle=True)
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

"""https://www.pluralsight.com/guides/introduction-to-resnet

https://towardsdatascience.com/implementing-alexnet-cnn-architecture-using-tensorflow-2-0-and-keras-2113e090ad98

https://gist.github.com/mohapatras/5d720cb19014ed573bcd3ed36c5929f5

https://www.pluralsight.com/guides/introduction-to-resnet

https://www.kaggle.com/kvpratama/pretrained-resnet18-in-pytorch
"""